{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wfdb import processing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv(\"y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.merge(data ,answers, on = \"Unnamed: 0\"))\n",
    "data['age'] = (data['age'] - data['age'].mean(axis = 0))/data['age'].std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop( [\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>i_0</th>\n",
       "      <th>i_1</th>\n",
       "      <th>i_2</th>\n",
       "      <th>i_3</th>\n",
       "      <th>i_4</th>\n",
       "      <th>i_5</th>\n",
       "      <th>i_6</th>\n",
       "      <th>i_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v6_4991</th>\n",
       "      <th>v6_4992</th>\n",
       "      <th>v6_4993</th>\n",
       "      <th>v6_4994</th>\n",
       "      <th>v6_4995</th>\n",
       "      <th>v6_4996</th>\n",
       "      <th>v6_4997</th>\n",
       "      <th>v6_4998</th>\n",
       "      <th>v6_4999</th>\n",
       "      <th>axis_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192357</td>\n",
       "      <td>1</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.399105</td>\n",
       "      <td>0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344253</td>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.453208</td>\n",
       "      <td>1</td>\n",
       "      <td>363.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    i_0    i_1    i_2    i_3    i_4    i_5    i_6    i_7  \\\n",
       "0  0.192357       1  -59.0  -58.0  -58.0  -58.0  -58.0  -58.0  -58.0  -58.0   \n",
       "1  1.399105       0  -39.0  -38.0  -38.0  -38.0  -38.0  -38.0  -38.0  -38.0   \n",
       "2  0.137505       0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  1.344253       0  108.0  106.0   93.0   79.0   86.0   74.0   64.0   51.0   \n",
       "4 -1.453208       1  363.0  366.0  366.0  353.0  334.0  314.0  306.0  294.0   \n",
       "\n",
       "    ...     v6_4991  v6_4992  v6_4993  v6_4994  v6_4995  v6_4996  v6_4997  \\\n",
       "0   ...       114.0    119.0    124.0    129.0    134.0    147.0    172.0   \n",
       "1   ...       229.0    259.0    289.0    319.0    349.0    379.0    409.0   \n",
       "2   ...       -58.0    -58.0    -58.0    -58.0    -58.0    -58.0    -38.0   \n",
       "3   ...        81.0     89.0     79.0     59.0     61.0     64.0     49.0   \n",
       "4   ...       -61.0    -59.0    -86.0    -66.0    -71.0    -91.0    -84.0   \n",
       "\n",
       "   v6_4998  v6_4999  axis_id  \n",
       "0    200.0    143.0        3  \n",
       "1    439.0    302.0        3  \n",
       "2    -11.0     -2.0        2  \n",
       "3     26.0     10.0        3  \n",
       "4    -11.0     -4.0        0  \n",
       "\n",
       "[5 rows x 60003 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df = pd.read_csv(\"signal_data.csv\", sep=\"#\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in signal_df.columns:\n",
    "    signal_df[column] = signal_df[column].apply(lambda row: np.fromstring(row[1:-1], sep=\"  \", dtype=np.uint64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(FixedLengthDataset):\n",
    "    def __init__(self, data, peaks, signal_length, min_start_offset = 50, max_start_offset = 300, low_cut = 5, high_cut = 20):\n",
    "        super().__init__(data, peaks, signal_length, min_start_offset, max_start_offset, low_cut, high_cut)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        true_idx, cut_point = self.cut_points[idx]\n",
    "        label = self._get_label(true_idx)\n",
    "        cut_rows = self._cut(self.filtered_data[true_idx], cut_point)\n",
    "        \n",
    "        return np.transpose(cut_rows), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestECGDataset(FixedLengthDataset):\n",
    "    def __init__(self, data, peaks, signal_length, min_start_offset = 50, max_start_offset = 300, low_cut = 5, high_cut = 20):\n",
    "        super().__init__(data, peaks, signal_length, min_start_offset, max_start_offset, low_cut, high_cut)\n",
    "               \n",
    "    def _get_cuts(self):\n",
    "        cut_points = [ self._get_peaks_for_signal_cuts(peaks[0])  for peaks in self.peaks]\n",
    "        self.cut_points = cut_points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        cut_point = np.random.choice(self.cut_points[idx])\n",
    "        label = self._get_label(idx)\n",
    "        cut_rows = self._cut(self.filtered_data[idx], cut_point)\n",
    "        \n",
    "        return np.transpose(cut_rows), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "dataset = TestECGDataset(data, signal_df, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_loader = DataLoader(dataset, batch_size= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3000, 12])\n",
      "tensor([3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i in ecg_loader:\n",
    "    print(i[0].shape)\n",
    "    print(i[1].argmax(dim=1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.1\n",
    "random_seed = 7\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_dataset = ECGDataset(data.iloc[train_idx], signal_df.iloc[train_idx], 3000)\n",
    "valid_dataset = TestECGDataset(data.iloc[valid_idx], signal_df.iloc[valid_idx], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batchsize, shuffle = True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=batchsize, shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_length, hidden_size=100, num_layers=1, bidirectional=False):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seq_length = seq_length\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = 12,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            bidirectional = bidirectional\n",
    "        )\n",
    "        self.dense = nn.Linear(hidden_size, 4)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        k = 2 if self.bidirectional else 1\n",
    "        return torch.zeros((self.num_layers * k, self.seq_length, self.hidden_size), dtype = \ttorch.float)\n",
    "        \n",
    "    def forward(self, x, h0):\n",
    "        x = x.float()\n",
    "        outputs, hn = self.gru(x, h0)\n",
    "        feature = outputs[:,-1,:]\n",
    "        result = self.dense(feature)\n",
    "        result = self.sm(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(3000, num_layers = 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    val_length = 0\n",
    "    correct_answers = 0\n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        # get the inputs\n",
    "        (sequences, labels) = data\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device).argmax(dim = 1)\n",
    "        h0 = model.init_hidden().to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        preds = model.forward(sequences, h0)\n",
    "\n",
    "        answer = preds.argmax(dim = 1)\n",
    "\n",
    "        res = answer == labels \n",
    "\n",
    "        #print(answer)\n",
    "        ##print(res)\n",
    "        #print(np.sum(res)/len(answer))\n",
    "        val_length += len(answer)\n",
    "        correct_answers += res.sum().float()\n",
    "        \n",
    "    return correct_answers/val_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [10/57], Loss: 1.2629\n",
      "Epoch [1/1000], Step [20/57], Loss: 1.2522\n",
      "Epoch [1/1000], Step [30/57], Loss: 1.2403\n",
      "Epoch [1/1000], Step [40/57], Loss: 1.1222\n",
      "Epoch [1/1000], Step [50/57], Loss: 1.2074\n",
      "Epoch [1/1000], Score: 0.5076923370361328\n",
      "Epoch [31/1000], Step [10/57], Loss: 1.2497\n",
      "Epoch [31/1000], Step [20/57], Loss: 1.2090\n",
      "Epoch [31/1000], Step [30/57], Loss: 1.3005\n",
      "Epoch [31/1000], Step [40/57], Loss: 1.2819\n",
      "Epoch [31/1000], Step [50/57], Loss: 1.1913\n",
      "Epoch [31/1000], Score: 0.4000000059604645\n",
      "Epoch [61/1000], Step [10/57], Loss: 1.2904\n",
      "Epoch [61/1000], Step [20/57], Loss: 1.2738\n",
      "Epoch [61/1000], Step [30/57], Loss: 1.2769\n",
      "Epoch [61/1000], Step [40/57], Loss: 1.1891\n",
      "Epoch [61/1000], Step [50/57], Loss: 1.2258\n",
      "Epoch [61/1000], Score: 0.4307692348957062\n",
      "Epoch [91/1000], Step [10/57], Loss: 1.2317\n",
      "Epoch [91/1000], Step [20/57], Loss: 1.2004\n",
      "Epoch [91/1000], Step [30/57], Loss: 1.2062\n",
      "Epoch [91/1000], Step [40/57], Loss: 1.2939\n",
      "Epoch [91/1000], Step [50/57], Loss: 1.2169\n",
      "Epoch [91/1000], Score: 0.4000000059604645\n",
      "Epoch [121/1000], Step [10/57], Loss: 1.1891\n",
      "Epoch [121/1000], Step [20/57], Loss: 1.2336\n",
      "Epoch [121/1000], Step [30/57], Loss: 1.2563\n",
      "Epoch [121/1000], Step [40/57], Loss: 1.3256\n",
      "Epoch [121/1000], Step [50/57], Loss: 1.2353\n",
      "Epoch [121/1000], Score: 0.4923076927661896\n",
      "Epoch [151/1000], Step [10/57], Loss: 1.2392\n",
      "Epoch [151/1000], Step [20/57], Loss: 1.2492\n",
      "Epoch [151/1000], Step [30/57], Loss: 1.2089\n",
      "Epoch [151/1000], Step [40/57], Loss: 1.1580\n",
      "Epoch [151/1000], Step [50/57], Loss: 1.2001\n",
      "Epoch [151/1000], Score: 0.4307692348957062\n",
      "Epoch [181/1000], Step [10/57], Loss: 1.2430\n",
      "Epoch [181/1000], Step [20/57], Loss: 1.1996\n",
      "Epoch [181/1000], Step [30/57], Loss: 1.2323\n",
      "Epoch [181/1000], Step [40/57], Loss: 1.2451\n",
      "Epoch [181/1000], Step [50/57], Loss: 1.2924\n",
      "Epoch [181/1000], Score: 0.5076923370361328\n",
      "Epoch [211/1000], Step [10/57], Loss: 1.1131\n",
      "Epoch [211/1000], Step [20/57], Loss: 1.0819\n",
      "Epoch [211/1000], Step [30/57], Loss: 1.2326\n",
      "Epoch [211/1000], Step [40/57], Loss: 1.2483\n",
      "Epoch [211/1000], Step [50/57], Loss: 1.1537\n",
      "Epoch [211/1000], Score: 0.5538461804389954\n",
      "Epoch [241/1000], Step [10/57], Loss: 1.2847\n",
      "Epoch [241/1000], Step [20/57], Loss: 1.2508\n",
      "Epoch [241/1000], Step [30/57], Loss: 1.1775\n",
      "Epoch [241/1000], Step [40/57], Loss: 1.2217\n",
      "Epoch [241/1000], Step [50/57], Loss: 1.2384\n",
      "Epoch [241/1000], Score: 0.4153846204280853\n",
      "Epoch [271/1000], Step [10/57], Loss: 1.2336\n",
      "Epoch [271/1000], Step [20/57], Loss: 1.2791\n",
      "Epoch [271/1000], Step [30/57], Loss: 1.2189\n",
      "Epoch [271/1000], Step [40/57], Loss: 1.2663\n",
      "Epoch [271/1000], Step [50/57], Loss: 1.1919\n",
      "Epoch [271/1000], Score: 0.4769230782985687\n",
      "Epoch [301/1000], Step [10/57], Loss: 1.2241\n",
      "Epoch [301/1000], Step [20/57], Loss: 1.2286\n",
      "Epoch [301/1000], Step [30/57], Loss: 1.1819\n",
      "Epoch [301/1000], Step [40/57], Loss: 1.2061\n",
      "Epoch [301/1000], Step [50/57], Loss: 1.3191\n",
      "Epoch [301/1000], Score: 0.4615384638309479\n",
      "Epoch [331/1000], Step [10/57], Loss: 1.1992\n",
      "Epoch [331/1000], Step [20/57], Loss: 1.2053\n",
      "Epoch [331/1000], Step [30/57], Loss: 1.2876\n",
      "Epoch [331/1000], Step [40/57], Loss: 1.1543\n",
      "Epoch [331/1000], Step [50/57], Loss: 1.3699\n",
      "Epoch [331/1000], Score: 0.4000000059604645\n",
      "Epoch [361/1000], Step [10/57], Loss: 1.1902\n",
      "Epoch [361/1000], Step [20/57], Loss: 1.2999\n",
      "Epoch [361/1000], Step [30/57], Loss: 1.2496\n",
      "Epoch [361/1000], Step [40/57], Loss: 1.2499\n",
      "Epoch [361/1000], Step [50/57], Loss: 1.1405\n",
      "Epoch [361/1000], Score: 0.446153849363327\n",
      "Epoch [391/1000], Step [10/57], Loss: 1.2319\n",
      "Epoch [391/1000], Step [20/57], Loss: 1.2232\n",
      "Epoch [391/1000], Step [30/57], Loss: 1.2236\n",
      "Epoch [391/1000], Step [40/57], Loss: 1.1517\n",
      "Epoch [391/1000], Step [50/57], Loss: 1.1525\n",
      "Epoch [391/1000], Score: 0.4307692348957062\n",
      "Epoch [421/1000], Step [10/57], Loss: 1.2764\n",
      "Epoch [421/1000], Step [20/57], Loss: 1.2065\n",
      "Epoch [421/1000], Step [30/57], Loss: 1.1741\n",
      "Epoch [421/1000], Step [40/57], Loss: 1.2826\n",
      "Epoch [421/1000], Step [50/57], Loss: 1.1494\n",
      "Epoch [421/1000], Score: 0.3384615480899811\n",
      "Epoch [451/1000], Step [10/57], Loss: 1.1460\n",
      "Epoch [451/1000], Step [20/57], Loss: 1.1769\n",
      "Epoch [451/1000], Step [30/57], Loss: 1.1445\n",
      "Epoch [451/1000], Step [40/57], Loss: 1.2368\n",
      "Epoch [451/1000], Step [50/57], Loss: 1.2339\n",
      "Epoch [451/1000], Score: 0.446153849363327\n",
      "Epoch [481/1000], Step [10/57], Loss: 1.2797\n",
      "Epoch [481/1000], Step [20/57], Loss: 1.2472\n",
      "Epoch [481/1000], Step [30/57], Loss: 1.2512\n",
      "Epoch [481/1000], Step [40/57], Loss: 1.2529\n",
      "Epoch [481/1000], Step [50/57], Loss: 1.2532\n",
      "Epoch [481/1000], Score: 0.4615384638309479\n",
      "Epoch [511/1000], Step [10/57], Loss: 1.1847\n",
      "Epoch [511/1000], Step [20/57], Loss: 1.0839\n",
      "Epoch [511/1000], Step [30/57], Loss: 1.1725\n",
      "Epoch [511/1000], Step [40/57], Loss: 1.3131\n",
      "Epoch [511/1000], Step [50/57], Loss: 1.1350\n",
      "Epoch [511/1000], Score: 0.4923076927661896\n",
      "Epoch [541/1000], Step [10/57], Loss: 1.2409\n",
      "Epoch [541/1000], Step [20/57], Loss: 1.2382\n",
      "Epoch [541/1000], Step [30/57], Loss: 1.2934\n",
      "Epoch [541/1000], Step [40/57], Loss: 1.2214\n",
      "Epoch [541/1000], Step [50/57], Loss: 1.2432\n",
      "Epoch [541/1000], Score: 0.3692307770252228\n",
      "Epoch [571/1000], Step [10/57], Loss: 1.2798\n",
      "Epoch [571/1000], Step [20/57], Loss: 1.2646\n",
      "Epoch [571/1000], Step [30/57], Loss: 1.2178\n",
      "Epoch [571/1000], Step [40/57], Loss: 1.1824\n",
      "Epoch [571/1000], Step [50/57], Loss: 1.2479\n",
      "Epoch [571/1000], Score: 0.446153849363327\n",
      "Epoch [601/1000], Step [10/57], Loss: 1.2978\n",
      "Epoch [601/1000], Step [20/57], Loss: 1.2272\n",
      "Epoch [601/1000], Step [30/57], Loss: 1.2112\n",
      "Epoch [601/1000], Step [40/57], Loss: 1.1893\n",
      "Epoch [601/1000], Step [50/57], Loss: 1.2273\n",
      "Epoch [601/1000], Score: 0.4615384638309479\n",
      "Epoch [631/1000], Step [10/57], Loss: 1.2593\n",
      "Epoch [631/1000], Step [20/57], Loss: 1.1984\n",
      "Epoch [631/1000], Step [30/57], Loss: 1.2061\n",
      "Epoch [631/1000], Step [40/57], Loss: 1.2419\n",
      "Epoch [631/1000], Step [50/57], Loss: 1.2427\n",
      "Epoch [631/1000], Score: 0.4307692348957062\n",
      "Epoch [661/1000], Step [10/57], Loss: 1.1618\n",
      "Epoch [661/1000], Step [20/57], Loss: 1.2200\n",
      "Epoch [661/1000], Step [30/57], Loss: 1.1932\n",
      "Epoch [661/1000], Step [40/57], Loss: 1.1693\n",
      "Epoch [661/1000], Step [50/57], Loss: 1.2017\n",
      "Epoch [661/1000], Score: 0.4769230782985687\n",
      "Epoch [691/1000], Step [10/57], Loss: 1.2930\n",
      "Epoch [691/1000], Step [20/57], Loss: 1.3111\n",
      "Epoch [691/1000], Step [30/57], Loss: 1.2881\n",
      "Epoch [691/1000], Step [40/57], Loss: 1.2434\n",
      "Epoch [691/1000], Step [50/57], Loss: 1.2895\n",
      "Epoch [691/1000], Score: 0.4769230782985687\n",
      "Epoch [721/1000], Step [10/57], Loss: 1.2528\n",
      "Epoch [721/1000], Step [20/57], Loss: 1.1640\n",
      "Epoch [721/1000], Step [30/57], Loss: 1.1615\n",
      "Epoch [721/1000], Step [40/57], Loss: 1.1968\n",
      "Epoch [721/1000], Step [50/57], Loss: 1.1673\n",
      "Epoch [721/1000], Score: 0.4153846204280853\n",
      "Epoch [751/1000], Step [10/57], Loss: 1.2931\n",
      "Epoch [751/1000], Step [20/57], Loss: 1.2109\n",
      "Epoch [751/1000], Step [30/57], Loss: 1.2662\n",
      "Epoch [751/1000], Step [40/57], Loss: 1.2087\n",
      "Epoch [751/1000], Step [50/57], Loss: 1.2693\n",
      "Epoch [751/1000], Score: 0.5230769515037537\n",
      "Epoch [781/1000], Step [10/57], Loss: 1.1805\n",
      "Epoch [781/1000], Step [20/57], Loss: 1.2327\n",
      "Epoch [781/1000], Step [30/57], Loss: 1.1341\n",
      "Epoch [781/1000], Step [40/57], Loss: 1.2475\n",
      "Epoch [781/1000], Step [50/57], Loss: 1.2401\n",
      "Epoch [781/1000], Score: 0.4769230782985687\n",
      "Epoch [811/1000], Step [10/57], Loss: 1.2456\n",
      "Epoch [811/1000], Step [20/57], Loss: 1.2108\n",
      "Epoch [811/1000], Step [30/57], Loss: 1.2071\n",
      "Epoch [811/1000], Step [40/57], Loss: 1.2389\n",
      "Epoch [811/1000], Step [50/57], Loss: 1.1726\n",
      "Epoch [811/1000], Score: 0.4615384638309479\n",
      "Epoch [841/1000], Step [10/57], Loss: 1.1289\n",
      "Epoch [841/1000], Step [20/57], Loss: 1.2168\n",
      "Epoch [841/1000], Step [30/57], Loss: 1.2296\n",
      "Epoch [841/1000], Step [40/57], Loss: 1.2554\n",
      "Epoch [841/1000], Step [50/57], Loss: 1.3027\n",
      "Epoch [841/1000], Score: 0.5230769515037537\n",
      "Epoch [871/1000], Step [10/57], Loss: 1.3090\n",
      "Epoch [871/1000], Step [20/57], Loss: 1.1538\n",
      "Epoch [871/1000], Step [30/57], Loss: 1.1435\n",
      "Epoch [871/1000], Step [40/57], Loss: 1.1282\n",
      "Epoch [871/1000], Step [50/57], Loss: 1.2693\n",
      "Epoch [871/1000], Score: 0.4153846204280853\n",
      "Epoch [901/1000], Step [10/57], Loss: 1.1268\n",
      "Epoch [901/1000], Step [20/57], Loss: 1.1977\n",
      "Epoch [901/1000], Step [30/57], Loss: 1.2724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [901/1000], Step [40/57], Loss: 1.3206\n",
      "Epoch [901/1000], Step [50/57], Loss: 1.2432\n",
      "Epoch [901/1000], Score: 0.5846154093742371\n",
      "Epoch [931/1000], Step [10/57], Loss: 1.3279\n",
      "Epoch [931/1000], Step [20/57], Loss: 1.2055\n",
      "Epoch [931/1000], Step [30/57], Loss: 1.1774\n",
      "Epoch [931/1000], Step [40/57], Loss: 1.2554\n",
      "Epoch [931/1000], Step [50/57], Loss: 1.0971\n",
      "Epoch [931/1000], Score: 0.5230769515037537\n",
      "Epoch [961/1000], Step [10/57], Loss: 1.2100\n",
      "Epoch [961/1000], Step [20/57], Loss: 1.2601\n",
      "Epoch [961/1000], Step [30/57], Loss: 1.1833\n",
      "Epoch [961/1000], Step [40/57], Loss: 1.2744\n",
      "Epoch [961/1000], Step [50/57], Loss: 1.1598\n",
      "Epoch [961/1000], Score: 0.4000000059604645\n",
      "Epoch [991/1000], Step [10/57], Loss: 1.1743\n",
      "Epoch [991/1000], Step [20/57], Loss: 1.2200\n",
      "Epoch [991/1000], Step [30/57], Loss: 1.2506\n",
      "Epoch [991/1000], Step [40/57], Loss: 1.2715\n",
      "Epoch [991/1000], Step [50/57], Loss: 1.1945\n",
      "Epoch [991/1000], Score: 0.4307692348957062\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(no_of_epochs):\n",
    "    model.train()\n",
    "    for i, (sequences, label) in enumerate(train_loader):\n",
    "        sequences = sequences.to(device)\n",
    "        label  = label.to(device).argmax(dim=1).long()\n",
    "        h0 = model.init_hidden().to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        preds = model(sequences, h0)\n",
    "        loss = criterion(preds, label)\n",
    "        \n",
    "        if (epoch%30==0 and i % 10 == 9):\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, no_of_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    if (epoch%30 == 0):\n",
    "        print('Epoch [{}/{}], Score: {}' \n",
    "                   .format(epoch+1, no_of_epochs, validate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4769, device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.,  0.,  0., 11.,  0.,  0., 20.,  0.,  0., 28.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADMpJREFUeJzt3V2MXHUZx/HfT1rUWCLFDrjBllVCjNVIwU1T08TUIKa2CYWISXuBxWCWqERIuGm4EPSqJAKJL4GUtKEaRAgvUmlRa8U0JFrdNgXaLEglVQtNu0CkJRpNy+PFnOJmme2cmTmzM/Pw/SSbnZeze55/D3w7e3Zm6ogQAGDwvafXAwAAqkHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkMWsmdzZv3rwYHh6eyV0CwMDbvXv3qxFRa7bdjAZ9eHhYY2NjM7lLABh4tv9WZjtOuQBAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASM/pKUQDopeF1W3u274PrV3Z9HzxCB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJJoG3fZ820/ZHre93/aNxe232X7Z9t7iY0X3xwUATKfMP0F3QtLNEbHH9lmSdtveXtx3V0R8v3vjAQDKahr0iDgs6XBx+bjtcUnnd3swAEBrWjqHbntY0iWSdhU33WD7WdubbM+teDYAQAtKB932HEmPSLopIo5JulvShZIWqf4I/o5pvm7U9pjtsYmJiQpGBgA0UirotmerHvP7I+JRSYqIIxFxMiLeknSvpMWNvjYiNkTESESM1Gq1quYGAExR5lkulrRR0nhE3Dnp9qFJm10laV/14wEAyirzLJelkq6R9JztvcVtt0haY3uRpJB0UNL1XZkQAFBKmWe5PC3JDe7aVv04AIB28UpRAEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQRNOg255v+ynb47b3276xuP0c29ttv1h8ntv9cQEA0ynzCP2EpJsj4hOSlkj6lu2FktZJ2hERF0naUVwHAPRI06BHxOGI2FNcPi5pXNL5klZJ2lxstlnSld0aEgDQXEvn0G0PS7pE0i5J50XEYakefUnnVj0cAKC8WWU3tD1H0iOSboqIY7bLft2opFFJWrBgQTszAqkNr9vak/0eXL+yJ/tF95R6hG57tuoxvz8iHi1uPmJ7qLh/SNLRRl8bERsiYiQiRmq1WhUzAwAaKPMsF0vaKGk8Iu6cdNcWSWuLy2slPV79eACAssqcclkq6RpJz9neW9x2i6T1kh6yfZ2kv0v6SndGBACU0TToEfG0pOlOmF9W7TgAgHbxSlEASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJBE06Db3mT7qO19k267zfbLtvcWHyu6OyYAoJkyj9Dvk7S8we13RcSi4mNbtWMBAFrVNOgRsVPS6zMwCwCgA52cQ7/B9rPFKZm5lU0EAGhLu0G/W9KFkhZJOizpjuk2tD1qe8z22MTERJu7AwA001bQI+JIRJyMiLck3Stp8Wm23RARIxExUqvV2p0TANBEW0G3PTTp6lWS9k23LQBgZsxqtoHtByQtkzTP9iFJt0paZnuRpJB0UNL1XZwRAFBC06BHxJoGN2/swiwAgA7wSlEASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJzOr1AOg/w+u29mzfB9ev7Nm+gUHHI3QASIKgA0ASBB0AkmgadNubbB+1vW/SbefY3m77xeLz3O6OCQBopswj9PskLZ9y2zpJOyLiIkk7iusAgB5qGvSI2Cnp9Sk3r5K0ubi8WdKVFc8FAGhRu+fQz4uIw5JUfD63upEAAO3o+i9FbY/aHrM9NjEx0e3dAcC7VrtBP2J7SJKKz0en2zAiNkTESESM1Gq1NncHAGim3aBvkbS2uLxW0uPVjAMAaFeZpy0+IOkPkj5u+5Dt6yStl3S57RclXV5cBwD0UNP3comINdPcdVnFswAAOsArRQEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACQxq9cDlDW8bmvP9n1w/cqe7RsAyuIROgAkQdABIAmCDgBJdHQO3fZBScclnZR0IiJGqhgKANC6Kn4p+vmIeLWC7wMA6ACnXAAgiU6DHpJ+Y3u37dEqBgIAtKfTUy5LI+IV2+dK2m77+YjYOXmDIvSjkrRgwYIOdwcAmE5Hj9Aj4pXi81FJj0la3GCbDRExEhEjtVqtk90BAE6j7aDb/oDts05dlvRFSfuqGgwA0JpOTrmcJ+kx26e+z88i4leVTAUAaFnbQY+IlyRdXOEsAIAO8LRFAEiCoANAEgQdAJIg6ACQBEEHgCQIOgAkQdABIAmCDgBJEHQASIKgA0ASBB0AkiDoAJAEQQeAJAg6ACRB0AEgCYIOAEkQdABIgqADQBIEHQCSIOgAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEgQdAJIg6ACQREdBt73c9gu2D9heV9VQAIDWtR1022dI+rGkL0laKGmN7YVVDQYAaE0nj9AXSzoQES9FxH8l/VzSqmrGAgC0qpOgny/pH5OuHypuAwD0wKwOvtYNbot3bGSPShotrr5p+4U29zdP0qttfm1HfHvl37Jna+mCStfShT/rst51x6SHf9atSHNcfHtHa7mgzEadBP2QpPmTrn9E0itTN4qIDZI2dLAfSZLtsYgY6fT79APW0n+yrENiLf1qJtbSySmXP0u6yPZHbZ8pabWkLdWMBQBoVduP0CPihO0bJP1a0hmSNkXE/somAwC0pJNTLoqIbZK2VTRLMx2ftukjrKX/ZFmHxFr6VdfX4oh3/B4TADCAeOk/ACTRd0Fv9nYCtt9r+8Hi/l22h2d+ynJKrOVa2xO29xYfX+/FnM3Y3mT7qO1909xv2z8o1vms7UtnesYySqxjme03Jh2P78z0jGXZnm/7KdvjtvfbvrHBNoNyXMqspe+Pje332f6T7WeKdXy3wTbd7VdE9M2H6r9c/aukj0k6U9IzkhZO2eabku4pLq+W9GCv5+5gLddK+lGvZy2xls9JulTSvmnuXyHpSdVfm7BE0q5ez9zmOpZJeqLXc5Zcy5CkS4vLZ0n6S4P/vgbluJRZS98fm+LPeU5xebakXZKWTNmmq/3qt0foZd5OYJWkzcXlhyVdZrvRi5x6Lc1bI0TETkmvn2aTVZJ+EnV/lHS27aGZma68EusYGBFxOCL2FJePSxrXO1+pPSjHpcxa+l7x5/xmcXV28TH1l5Rd7Ve/Bb3M2wm8vU1EnJD0hqQPzch0rSn71ghfLn4cftj2/Ab3D4JMbwPx2eJH5idtf7LXw5RR/Nh+ieqPCCcbuONymrVIA3BsbJ9he6+ko5K2R8S0x6Qb/eq3oJd5O4FSbznQB8rM+UtJwxHxaUm/1f//5h40g3JMmtkj6YKIuFjSDyX9osfzNGV7jqRHJN0UEcem3t3gS/r2uDRZy0Acm4g4GRGLVH/l/GLbn5qySVePSb8FvczbCby9je1Zkj6o/vwxuulaIuK1iPhPcfVeSZ+ZodmqVuptIPpdRBw79SNz1F9jMdv2vB6PNS3bs1UP4P0R8WiDTQbmuDRby6Adm4j4p6TfS1o+5a6u9qvfgl7m7QS2SFpbXL5a0u+i+A1Dn2m6linnM69Q/dzhINoi6avFsyqWSHojIg73eqhW2f7wqfOZther/v/Ha72dqrFizo2SxiPizmk2G4jjUmYtg3BsbNdsn11cfr+kL0h6fspmXe1XR68UrVpM83YCtr8naSwitqh+4H9q+4Dqf7Ot7t3E0yu5lm/bvkLSCdXXcm3PBj4N2w+o/iyDebYPSbpV9V/4KCLuUf3VwiskHZD0L0lf682kp1diHVdL+obtE5L+LWl1nz5YkKSlkq6R9FxxzlaSbpG0QBqs46JyaxmEYzMkabPr//jPeyQ9FBFPzGS/eKUoACTRb6dcAABtIugAkARBB4AkCDoAJEHQASAJgg4ASRB0AEiCoANAEv8DPpkXu3CFylIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[\"axis_id\"].values[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 75.,   0.,   0.,  74.,   0.,   0., 249.,   0.,   0., 196.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[\"axis_id\"].values[train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
