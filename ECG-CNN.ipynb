{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wfdb import processing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv(\"y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.merge(data ,answers, on = \"Unnamed: 0\"))\n",
    "data['age'] = (data['age'] - data['age'].mean(axis = 0))/data['age'].std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop( [\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>i_0</th>\n",
       "      <th>i_1</th>\n",
       "      <th>i_2</th>\n",
       "      <th>i_3</th>\n",
       "      <th>i_4</th>\n",
       "      <th>i_5</th>\n",
       "      <th>i_6</th>\n",
       "      <th>i_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v6_4991</th>\n",
       "      <th>v6_4992</th>\n",
       "      <th>v6_4993</th>\n",
       "      <th>v6_4994</th>\n",
       "      <th>v6_4995</th>\n",
       "      <th>v6_4996</th>\n",
       "      <th>v6_4997</th>\n",
       "      <th>v6_4998</th>\n",
       "      <th>v6_4999</th>\n",
       "      <th>axis_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192357</td>\n",
       "      <td>1</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.399105</td>\n",
       "      <td>0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344253</td>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.453208</td>\n",
       "      <td>1</td>\n",
       "      <td>363.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    i_0    i_1    i_2    i_3    i_4    i_5    i_6    i_7  \\\n",
       "0  0.192357       1  -59.0  -58.0  -58.0  -58.0  -58.0  -58.0  -58.0  -58.0   \n",
       "1  1.399105       0  -39.0  -38.0  -38.0  -38.0  -38.0  -38.0  -38.0  -38.0   \n",
       "2  0.137505       0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  1.344253       0  108.0  106.0   93.0   79.0   86.0   74.0   64.0   51.0   \n",
       "4 -1.453208       1  363.0  366.0  366.0  353.0  334.0  314.0  306.0  294.0   \n",
       "\n",
       "    ...     v6_4991  v6_4992  v6_4993  v6_4994  v6_4995  v6_4996  v6_4997  \\\n",
       "0   ...       114.0    119.0    124.0    129.0    134.0    147.0    172.0   \n",
       "1   ...       229.0    259.0    289.0    319.0    349.0    379.0    409.0   \n",
       "2   ...       -58.0    -58.0    -58.0    -58.0    -58.0    -58.0    -38.0   \n",
       "3   ...        81.0     89.0     79.0     59.0     61.0     64.0     49.0   \n",
       "4   ...       -61.0    -59.0    -86.0    -66.0    -71.0    -91.0    -84.0   \n",
       "\n",
       "   v6_4998  v6_4999  axis_id  \n",
       "0    200.0    143.0        3  \n",
       "1    439.0    302.0        3  \n",
       "2    -11.0     -2.0        2  \n",
       "3     26.0     10.0        3  \n",
       "4    -11.0     -4.0        0  \n",
       "\n",
       "[5 rows x 60003 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df = pd.read_csv(\"signal_data.csv\", sep=\"#\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in signal_df.columns:\n",
    "    signal_df[column] = signal_df[column].apply(lambda row: np.fromstring(row[1:-1], sep=\"  \", dtype=np.uint64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 64\n",
    "overlap = 32   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogramm(ecg, should_log = False, show = False):\n",
    "    f,t,x = signal.spectral.spectrogram(\n",
    "                        ecg, \n",
    "                        window=(\"tukey\", 0.25),\n",
    "                        nperseg=window_size, \n",
    "                        noverlap=overlap, \n",
    "                        return_onesided=True) \n",
    "    \n",
    "            \n",
    "    if (should_log):    \n",
    "        x = np.log(x + 1e-8)\n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    if (show):\n",
    "        plt.pcolormesh(t, f, x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spectro = get_spectrogramm(data.values[0][2:5002], False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(FixedLengthDataset):\n",
    "    def __init__(self, data, peaks, signal_length, min_start_offset = 50, max_start_offset = 300, low_cut = 5, high_cut = 20):\n",
    "        super().__init__(data, peaks, signal_length, min_start_offset, max_start_offset, low_cut, high_cut)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        true_idx, cut_point = self.cut_points[idx]\n",
    "        label = self._get_label(true_idx)\n",
    "        cut_rows = self._cut(self.filtered_data[true_idx], cut_point)\n",
    "        \n",
    "        images = np.zeros((12,33,92), dtype=np.float32)\n",
    "        for i in range(12):\n",
    "            images[i] = get_spectrogramm(cut_rows[i])\n",
    "        \n",
    "        return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestECGDataset(FixedLengthDataset):\n",
    "    def __init__(self, data, peaks, signal_length, min_start_offset = 50, max_start_offset = 300, low_cut = 5, high_cut = 20):\n",
    "        super().__init__(data, peaks, signal_length, min_start_offset, max_start_offset, low_cut, high_cut)\n",
    "               \n",
    "    def _get_cuts(self):\n",
    "        cut_points = [ self._get_peaks_for_signal_cuts(peaks[0])  for peaks in self.peaks]\n",
    "        self.cut_points = cut_points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        cut_point = np.random.choice(self.cut_points[idx])\n",
    "        label = self._get_label(idx)\n",
    "        cut_rows = self._cut(self.filtered_data[idx], cut_point)\n",
    "        \n",
    "        images = np.zeros((12,33,92), dtype=np.float32)\n",
    "        for i in range(12):\n",
    "            images[i] = get_spectrogramm(cut_rows[i])\n",
    "        \n",
    "        return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "dataset = TestECGDataset(data, signal_df, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_loader = DataLoader(dataset, batch_size= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 33, 92])\n",
      "tensor([3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i in ecg_loader:\n",
    "    print(i[0].shape)\n",
    "    print(i[1].argmax(dim=1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.1\n",
    "random_seed = 7\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_dataset = ECGDataset(data.iloc[train_idx], signal_df.iloc[train_idx], 3000)\n",
    "valid_dataset = TestECGDataset(data.iloc[valid_idx], signal_df.iloc[valid_idx], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batchsize, shuffle = True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=batchsize, shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    # (33, 92)\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(12, 32, kernel_size=3, stride=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()) # (14, 44, 32)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()) # (5, 20, 32)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()) #(1, 8, 64)\n",
    "        self.fc1 = nn.Linear(8*64, 100)\n",
    "        self.fc2 = nn.Linear(100, 4)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    val_length = 0\n",
    "    correct_answers = 0\n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        # get the inputs\n",
    "        (images, labels) = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).argmax(dim = 1)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model.forward(images)\n",
    "\n",
    "\n",
    "        answer = outputs.argmax(dim = 1)\n",
    "\n",
    "        res = answer == labels \n",
    "\n",
    "        #print(answer)\n",
    "        ##print(res)\n",
    "        #print(np.sum(res)/len(answer))\n",
    "        val_length += len(answer)\n",
    "        correct_answers += res.sum().float()\n",
    "        \n",
    "    return correct_answers/val_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Step [10/57], Loss: 1.3748\n",
      "Epoch [1/150], Step [20/57], Loss: 1.3584\n",
      "Epoch [1/150], Step [30/57], Loss: 1.3262\n",
      "Epoch [1/150], Step [40/57], Loss: 1.2712\n",
      "Epoch [1/150], Step [50/57], Loss: 1.2236\n",
      "Epoch [1/150], Score: 0.6000000238418579\n",
      "Epoch [4/150], Step [10/57], Loss: 0.9919\n",
      "Epoch [4/150], Step [20/57], Loss: 1.1009\n",
      "Epoch [4/150], Step [30/57], Loss: 1.0561\n",
      "Epoch [4/150], Step [40/57], Loss: 1.0368\n",
      "Epoch [4/150], Step [50/57], Loss: 0.9762\n",
      "Epoch [4/150], Score: 0.6153846383094788\n",
      "Epoch [7/150], Step [10/57], Loss: 1.0124\n",
      "Epoch [7/150], Step [20/57], Loss: 1.0142\n",
      "Epoch [7/150], Step [30/57], Loss: 0.9824\n",
      "Epoch [7/150], Step [40/57], Loss: 0.9868\n",
      "Epoch [7/150], Step [50/57], Loss: 0.9528\n",
      "Epoch [7/150], Score: 0.6307692527770996\n",
      "Epoch [10/150], Step [10/57], Loss: 1.0494\n",
      "Epoch [10/150], Step [20/57], Loss: 1.0513\n",
      "Epoch [10/150], Step [30/57], Loss: 1.0871\n",
      "Epoch [10/150], Step [40/57], Loss: 0.9797\n",
      "Epoch [10/150], Step [50/57], Loss: 0.9819\n",
      "Epoch [10/150], Score: 0.692307710647583\n",
      "Epoch [13/150], Step [10/57], Loss: 1.0013\n",
      "Epoch [13/150], Step [20/57], Loss: 0.9607\n",
      "Epoch [13/150], Step [30/57], Loss: 0.9395\n",
      "Epoch [13/150], Step [40/57], Loss: 0.9353\n",
      "Epoch [13/150], Step [50/57], Loss: 0.9444\n",
      "Epoch [13/150], Score: 0.6615384817123413\n",
      "Epoch [16/150], Step [10/57], Loss: 1.0056\n",
      "Epoch [16/150], Step [20/57], Loss: 1.0069\n",
      "Epoch [16/150], Step [30/57], Loss: 1.0082\n",
      "Epoch [16/150], Step [40/57], Loss: 0.9435\n",
      "Epoch [16/150], Step [50/57], Loss: 0.9922\n",
      "Epoch [16/150], Score: 0.6769230961799622\n",
      "Epoch [19/150], Step [10/57], Loss: 0.9360\n",
      "Epoch [19/150], Step [20/57], Loss: 1.0330\n",
      "Epoch [19/150], Step [30/57], Loss: 0.9571\n",
      "Epoch [19/150], Step [40/57], Loss: 1.0123\n",
      "Epoch [19/150], Step [50/57], Loss: 0.9675\n",
      "Epoch [19/150], Score: 0.6769230961799622\n",
      "Epoch [22/150], Step [10/57], Loss: 1.0150\n",
      "Epoch [22/150], Step [20/57], Loss: 0.9771\n",
      "Epoch [22/150], Step [30/57], Loss: 0.9407\n",
      "Epoch [22/150], Step [40/57], Loss: 0.9641\n",
      "Epoch [22/150], Step [50/57], Loss: 0.9051\n",
      "Epoch [22/150], Score: 0.6769230961799622\n",
      "Epoch [25/150], Step [10/57], Loss: 0.9498\n",
      "Epoch [25/150], Step [20/57], Loss: 0.9101\n",
      "Epoch [25/150], Step [30/57], Loss: 0.9465\n",
      "Epoch [25/150], Step [40/57], Loss: 0.9571\n",
      "Epoch [25/150], Step [50/57], Loss: 0.9995\n",
      "Epoch [25/150], Score: 0.6615384817123413\n",
      "Epoch [28/150], Step [10/57], Loss: 0.9670\n",
      "Epoch [28/150], Step [20/57], Loss: 0.9649\n",
      "Epoch [28/150], Step [30/57], Loss: 0.9520\n",
      "Epoch [28/150], Step [40/57], Loss: 0.8784\n",
      "Epoch [28/150], Step [50/57], Loss: 0.8646\n",
      "Epoch [28/150], Score: 0.6769230961799622\n",
      "Epoch [31/150], Step [10/57], Loss: 0.9146\n",
      "Epoch [31/150], Step [20/57], Loss: 0.8902\n",
      "Epoch [31/150], Step [30/57], Loss: 0.9942\n",
      "Epoch [31/150], Step [40/57], Loss: 0.9863\n",
      "Epoch [31/150], Step [50/57], Loss: 0.9689\n",
      "Epoch [31/150], Score: 0.6615384817123413\n",
      "Epoch [34/150], Step [10/57], Loss: 0.9330\n",
      "Epoch [34/150], Step [20/57], Loss: 0.9136\n",
      "Epoch [34/150], Step [30/57], Loss: 0.9027\n",
      "Epoch [34/150], Step [40/57], Loss: 0.8787\n",
      "Epoch [34/150], Step [50/57], Loss: 0.9229\n",
      "Epoch [34/150], Score: 0.692307710647583\n",
      "Epoch [37/150], Step [10/57], Loss: 0.9160\n",
      "Epoch [37/150], Step [20/57], Loss: 0.9191\n",
      "Epoch [37/150], Step [30/57], Loss: 0.9106\n",
      "Epoch [37/150], Step [40/57], Loss: 0.9437\n",
      "Epoch [37/150], Step [50/57], Loss: 0.8939\n",
      "Epoch [37/150], Score: 0.6461538672447205\n",
      "Epoch [40/150], Step [10/57], Loss: 0.9543\n",
      "Epoch [40/150], Step [20/57], Loss: 0.8767\n",
      "Epoch [40/150], Step [30/57], Loss: 0.8671\n",
      "Epoch [40/150], Step [40/57], Loss: 0.8981\n",
      "Epoch [40/150], Step [50/57], Loss: 0.8779\n",
      "Epoch [40/150], Score: 0.6153846383094788\n",
      "Epoch [43/150], Step [10/57], Loss: 0.9126\n",
      "Epoch [43/150], Step [20/57], Loss: 0.8307\n",
      "Epoch [43/150], Step [30/57], Loss: 0.8533\n",
      "Epoch [43/150], Step [40/57], Loss: 0.8601\n",
      "Epoch [43/150], Step [50/57], Loss: 0.9711\n",
      "Epoch [43/150], Score: 0.6461538672447205\n",
      "Epoch [46/150], Step [10/57], Loss: 0.9265\n",
      "Epoch [46/150], Step [20/57], Loss: 0.9458\n",
      "Epoch [46/150], Step [30/57], Loss: 0.8862\n",
      "Epoch [46/150], Step [40/57], Loss: 0.8891\n",
      "Epoch [46/150], Step [50/57], Loss: 0.8953\n",
      "Epoch [46/150], Score: 0.6307692527770996\n",
      "Epoch [49/150], Step [10/57], Loss: 0.9285\n",
      "Epoch [49/150], Step [20/57], Loss: 0.9061\n",
      "Epoch [49/150], Step [30/57], Loss: 0.8848\n",
      "Epoch [49/150], Step [40/57], Loss: 0.8904\n",
      "Epoch [49/150], Step [50/57], Loss: 0.8477\n",
      "Epoch [49/150], Score: 0.5692307949066162\n",
      "Epoch [52/150], Step [10/57], Loss: 0.8801\n",
      "Epoch [52/150], Step [20/57], Loss: 0.9115\n",
      "Epoch [52/150], Step [30/57], Loss: 0.8442\n",
      "Epoch [52/150], Step [40/57], Loss: 0.8466\n",
      "Epoch [52/150], Step [50/57], Loss: 0.8907\n",
      "Epoch [52/150], Score: 0.6153846383094788\n",
      "Epoch [55/150], Step [10/57], Loss: 0.7898\n",
      "Epoch [55/150], Step [20/57], Loss: 0.8134\n",
      "Epoch [55/150], Step [30/57], Loss: 0.8245\n",
      "Epoch [55/150], Step [40/57], Loss: 0.8639\n",
      "Epoch [55/150], Step [50/57], Loss: 0.8951\n",
      "Epoch [55/150], Score: 0.6153846383094788\n",
      "Epoch [58/150], Step [10/57], Loss: 0.8629\n",
      "Epoch [58/150], Step [20/57], Loss: 0.8684\n",
      "Epoch [58/150], Step [30/57], Loss: 0.8384\n",
      "Epoch [58/150], Step [40/57], Loss: 0.7937\n",
      "Epoch [58/150], Step [50/57], Loss: 0.9830\n",
      "Epoch [58/150], Score: 0.6000000238418579\n",
      "Epoch [61/150], Step [10/57], Loss: 0.8789\n",
      "Epoch [61/150], Step [20/57], Loss: 0.8170\n",
      "Epoch [61/150], Step [30/57], Loss: 0.8663\n",
      "Epoch [61/150], Step [40/57], Loss: 0.8122\n",
      "Epoch [61/150], Step [50/57], Loss: 0.9454\n",
      "Epoch [61/150], Score: 0.5846154093742371\n",
      "Epoch [64/150], Step [10/57], Loss: 0.8267\n",
      "Epoch [64/150], Step [20/57], Loss: 0.8988\n",
      "Epoch [64/150], Step [30/57], Loss: 0.8240\n",
      "Epoch [64/150], Step [40/57], Loss: 0.8493\n",
      "Epoch [64/150], Step [50/57], Loss: 0.8581\n",
      "Epoch [64/150], Score: 0.6153846383094788\n",
      "Epoch [67/150], Step [10/57], Loss: 0.7706\n",
      "Epoch [67/150], Step [20/57], Loss: 0.8418\n",
      "Epoch [67/150], Step [30/57], Loss: 0.8341\n",
      "Epoch [67/150], Step [40/57], Loss: 0.8055\n",
      "Epoch [67/150], Step [50/57], Loss: 0.7919\n",
      "Epoch [67/150], Score: 0.5538461804389954\n",
      "Epoch [70/150], Step [10/57], Loss: 0.8430\n",
      "Epoch [70/150], Step [20/57], Loss: 0.9120\n",
      "Epoch [70/150], Step [30/57], Loss: 0.8080\n",
      "Epoch [70/150], Step [40/57], Loss: 0.8127\n",
      "Epoch [70/150], Step [50/57], Loss: 0.8227\n",
      "Epoch [70/150], Score: 0.5846154093742371\n",
      "Epoch [73/150], Step [10/57], Loss: 0.8090\n",
      "Epoch [73/150], Step [20/57], Loss: 0.8277\n",
      "Epoch [73/150], Step [30/57], Loss: 0.7978\n",
      "Epoch [73/150], Step [40/57], Loss: 0.8228\n",
      "Epoch [73/150], Step [50/57], Loss: 0.8874\n",
      "Epoch [73/150], Score: 0.5538461804389954\n",
      "Epoch [76/150], Step [10/57], Loss: 0.8782\n",
      "Epoch [76/150], Step [20/57], Loss: 0.8369\n",
      "Epoch [76/150], Step [30/57], Loss: 0.8403\n",
      "Epoch [76/150], Step [40/57], Loss: 0.8526\n",
      "Epoch [76/150], Step [50/57], Loss: 0.8341\n",
      "Epoch [76/150], Score: 0.5538461804389954\n",
      "Epoch [79/150], Step [10/57], Loss: 0.7842\n",
      "Epoch [79/150], Step [20/57], Loss: 0.8094\n",
      "Epoch [79/150], Step [30/57], Loss: 0.7794\n",
      "Epoch [79/150], Step [40/57], Loss: 0.8614\n",
      "Epoch [79/150], Step [50/57], Loss: 0.7688\n",
      "Epoch [79/150], Score: 0.5538461804389954\n",
      "Epoch [82/150], Step [10/57], Loss: 0.7939\n",
      "Epoch [82/150], Step [20/57], Loss: 0.8272\n",
      "Epoch [82/150], Step [30/57], Loss: 0.8724\n",
      "Epoch [82/150], Step [40/57], Loss: 0.8278\n",
      "Epoch [82/150], Step [50/57], Loss: 0.8156\n",
      "Epoch [82/150], Score: 0.6461538672447205\n",
      "Epoch [85/150], Step [10/57], Loss: 0.8288\n",
      "Epoch [85/150], Step [20/57], Loss: 0.8168\n",
      "Epoch [85/150], Step [30/57], Loss: 0.8218\n",
      "Epoch [85/150], Step [40/57], Loss: 0.8263\n",
      "Epoch [85/150], Step [50/57], Loss: 0.7502\n",
      "Epoch [85/150], Score: 0.6307692527770996\n",
      "Epoch [88/150], Step [10/57], Loss: 0.8102\n",
      "Epoch [88/150], Step [20/57], Loss: 0.7926\n",
      "Epoch [88/150], Step [30/57], Loss: 0.7729\n",
      "Epoch [88/150], Step [40/57], Loss: 0.8341\n",
      "Epoch [88/150], Step [50/57], Loss: 0.7894\n",
      "Epoch [88/150], Score: 0.5384615659713745\n",
      "Epoch [91/150], Step [10/57], Loss: 0.7910\n",
      "Epoch [91/150], Step [20/57], Loss: 0.7665\n",
      "Epoch [91/150], Step [30/57], Loss: 0.7614\n",
      "Epoch [91/150], Step [40/57], Loss: 0.8363\n",
      "Epoch [91/150], Step [50/57], Loss: 0.7600\n",
      "Epoch [91/150], Score: 0.6307692527770996\n",
      "Epoch [94/150], Step [10/57], Loss: 0.8184\n",
      "Epoch [94/150], Step [20/57], Loss: 0.7686\n",
      "Epoch [94/150], Step [30/57], Loss: 0.8563\n",
      "Epoch [94/150], Step [40/57], Loss: 0.8252\n",
      "Epoch [94/150], Step [50/57], Loss: 0.8210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/150], Score: 0.6307692527770996\n",
      "Epoch [97/150], Step [10/57], Loss: 0.8026\n",
      "Epoch [97/150], Step [20/57], Loss: 0.8112\n",
      "Epoch [97/150], Step [30/57], Loss: 0.7907\n",
      "Epoch [97/150], Step [40/57], Loss: 0.8209\n",
      "Epoch [97/150], Step [50/57], Loss: 0.8379\n",
      "Epoch [97/150], Score: 0.6461538672447205\n",
      "Epoch [100/150], Step [10/57], Loss: 0.7934\n",
      "Epoch [100/150], Step [20/57], Loss: 0.7782\n",
      "Epoch [100/150], Step [30/57], Loss: 0.8006\n",
      "Epoch [100/150], Step [40/57], Loss: 0.8015\n",
      "Epoch [100/150], Step [50/57], Loss: 0.8103\n",
      "Epoch [100/150], Score: 0.6000000238418579\n",
      "Epoch [103/150], Step [10/57], Loss: 0.8545\n",
      "Epoch [103/150], Step [20/57], Loss: 0.8048\n",
      "Epoch [103/150], Step [30/57], Loss: 0.7604\n",
      "Epoch [103/150], Step [40/57], Loss: 0.7834\n",
      "Epoch [103/150], Step [50/57], Loss: 0.7934\n",
      "Epoch [103/150], Score: 0.5538461804389954\n",
      "Epoch [106/150], Step [10/57], Loss: 0.7995\n",
      "Epoch [106/150], Step [20/57], Loss: 0.8025\n",
      "Epoch [106/150], Step [30/57], Loss: 0.7996\n",
      "Epoch [106/150], Step [40/57], Loss: 0.8044\n",
      "Epoch [106/150], Step [50/57], Loss: 0.7815\n",
      "Epoch [106/150], Score: 0.6153846383094788\n",
      "Epoch [109/150], Step [10/57], Loss: 0.7474\n",
      "Epoch [109/150], Step [20/57], Loss: 0.7983\n",
      "Epoch [109/150], Step [30/57], Loss: 0.7597\n",
      "Epoch [109/150], Step [40/57], Loss: 0.8242\n",
      "Epoch [109/150], Step [50/57], Loss: 0.7913\n",
      "Epoch [109/150], Score: 0.6307692527770996\n",
      "Epoch [112/150], Step [10/57], Loss: 0.7722\n",
      "Epoch [112/150], Step [20/57], Loss: 0.7943\n",
      "Epoch [112/150], Step [30/57], Loss: 0.7745\n",
      "Epoch [112/150], Step [40/57], Loss: 0.7964\n",
      "Epoch [112/150], Step [50/57], Loss: 0.7763\n",
      "Epoch [112/150], Score: 0.5692307949066162\n",
      "Epoch [115/150], Step [10/57], Loss: 0.8151\n",
      "Epoch [115/150], Step [20/57], Loss: 0.7443\n",
      "Epoch [115/150], Step [30/57], Loss: 0.7561\n",
      "Epoch [115/150], Step [40/57], Loss: 0.7992\n",
      "Epoch [115/150], Step [50/57], Loss: 0.7755\n",
      "Epoch [115/150], Score: 0.6153846383094788\n",
      "Epoch [118/150], Step [10/57], Loss: 0.8479\n",
      "Epoch [118/150], Step [20/57], Loss: 0.7628\n",
      "Epoch [118/150], Step [30/57], Loss: 0.7625\n",
      "Epoch [118/150], Step [40/57], Loss: 0.7778\n",
      "Epoch [118/150], Step [50/57], Loss: 0.7778\n",
      "Epoch [118/150], Score: 0.6000000238418579\n",
      "Epoch [121/150], Step [10/57], Loss: 0.8245\n",
      "Epoch [121/150], Step [20/57], Loss: 0.7934\n",
      "Epoch [121/150], Step [30/57], Loss: 0.7839\n",
      "Epoch [121/150], Step [40/57], Loss: 0.7452\n",
      "Epoch [121/150], Step [50/57], Loss: 0.8005\n",
      "Epoch [121/150], Score: 0.5846154093742371\n",
      "Epoch [124/150], Step [10/57], Loss: 0.7814\n",
      "Epoch [124/150], Step [20/57], Loss: 0.7912\n",
      "Epoch [124/150], Step [30/57], Loss: 0.7619\n",
      "Epoch [124/150], Step [40/57], Loss: 0.8692\n",
      "Epoch [124/150], Step [50/57], Loss: 0.7844\n",
      "Epoch [124/150], Score: 0.6000000238418579\n",
      "Epoch [127/150], Step [10/57], Loss: 0.7608\n",
      "Epoch [127/150], Step [20/57], Loss: 0.8070\n",
      "Epoch [127/150], Step [30/57], Loss: 0.7909\n",
      "Epoch [127/150], Step [40/57], Loss: 0.7806\n",
      "Epoch [127/150], Step [50/57], Loss: 0.7650\n",
      "Epoch [127/150], Score: 0.6000000238418579\n",
      "Epoch [130/150], Step [10/57], Loss: 0.7691\n",
      "Epoch [130/150], Step [20/57], Loss: 0.8220\n",
      "Epoch [130/150], Step [30/57], Loss: 0.7916\n",
      "Epoch [130/150], Step [40/57], Loss: 0.7548\n",
      "Epoch [130/150], Step [50/57], Loss: 0.7763\n",
      "Epoch [130/150], Score: 0.5846154093742371\n",
      "Epoch [133/150], Step [10/57], Loss: 0.7907\n",
      "Epoch [133/150], Step [20/57], Loss: 0.7685\n",
      "Epoch [133/150], Step [30/57], Loss: 0.7598\n",
      "Epoch [133/150], Step [40/57], Loss: 0.7608\n",
      "Epoch [133/150], Step [50/57], Loss: 0.8337\n",
      "Epoch [133/150], Score: 0.5538461804389954\n",
      "Epoch [136/150], Step [10/57], Loss: 0.7751\n",
      "Epoch [136/150], Step [20/57], Loss: 0.7987\n",
      "Epoch [136/150], Step [30/57], Loss: 0.7984\n",
      "Epoch [136/150], Step [40/57], Loss: 0.7754\n",
      "Epoch [136/150], Step [50/57], Loss: 0.7446\n",
      "Epoch [136/150], Score: 0.6307692527770996\n",
      "Epoch [139/150], Step [10/57], Loss: 0.7494\n",
      "Epoch [139/150], Step [20/57], Loss: 0.7601\n",
      "Epoch [139/150], Step [30/57], Loss: 0.7766\n",
      "Epoch [139/150], Step [40/57], Loss: 0.8376\n",
      "Epoch [139/150], Step [50/57], Loss: 0.7749\n",
      "Epoch [139/150], Score: 0.5846154093742371\n",
      "Epoch [142/150], Step [10/57], Loss: 0.7600\n",
      "Epoch [142/150], Step [20/57], Loss: 0.7438\n",
      "Epoch [142/150], Step [30/57], Loss: 0.7594\n",
      "Epoch [142/150], Step [40/57], Loss: 0.8224\n",
      "Epoch [142/150], Step [50/57], Loss: 0.8081\n",
      "Epoch [142/150], Score: 0.6461538672447205\n",
      "Epoch [145/150], Step [10/57], Loss: 0.7917\n",
      "Epoch [145/150], Step [20/57], Loss: 0.7678\n",
      "Epoch [145/150], Step [30/57], Loss: 0.8150\n",
      "Epoch [145/150], Step [40/57], Loss: 0.8223\n",
      "Epoch [145/150], Step [50/57], Loss: 0.7610\n",
      "Epoch [145/150], Score: 0.5692307949066162\n",
      "Epoch [148/150], Step [10/57], Loss: 0.7751\n",
      "Epoch [148/150], Step [20/57], Loss: 0.7650\n",
      "Epoch [148/150], Step [30/57], Loss: 0.8024\n",
      "Epoch [148/150], Step [40/57], Loss: 0.7648\n",
      "Epoch [148/150], Step [50/57], Loss: 0.8536\n",
      "Epoch [148/150], Score: 0.5692307949066162\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 150\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(no_of_epochs):\n",
    "    model.train()\n",
    "    for i, (images, label) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        label  = label.to(device).argmax(dim=1).long()\n",
    "\n",
    "        # Forward Pass\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, label)\n",
    "        \n",
    "        if (epoch%3==0 and i % 10 == 9):\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, no_of_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    if (epoch%3 == 0):\n",
    "        print('Epoch [{}/{}], Score: {}' \n",
    "                   .format(epoch+1, no_of_epochs, validate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5538, device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.,  0.,  0., 11.,  0.,  0., 20.,  0.,  0., 28.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[\"axis_id\"].values[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 75.,   0.,   0.,  74.,   0.,   0., 249.,   0.,   0., 196.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[\"axis_id\"].values[train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2689, 0.7311],\n",
       "        [0.1192, 0.8808]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([[2.0,3.0], [1.0, 3.0]]).float(), dim  = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[2,3],[2,2],[1,2]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
